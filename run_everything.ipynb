{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.4 64-bit",
   "display_name": "Python 3.7.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### This notebook serves the purpose of running everithing in one go - train, save the model where you want, resume training, see the predictions etc.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_preprocess_input import *\n",
    "from models import *\n",
    "from base_train import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sme-freecorpus.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# clean very special char\n",
    "text = text.replace(\"¶\", \"\").replace('•', '').replace('□', '').replace('§', '').replace('\\uf03d', '').replace('π', '').replace('●', '').replace('µ', '').replace('º', '').replace('文', '').replace('中', '').replace('⅞', '').replace('½', '').replace('⅓', '').replace('¾', '').replace('¹', '').replace('³', '').replace('\\t', '')\n",
    "# remove numbers\n",
    "text = re.sub(r'[0-9]+', '', text)\n",
    "# remove russian texts (it is in data)\n",
    "text = re.sub(r\"[А-Яа-я]\", '', text) \n",
    "# remove puctuation\n",
    "text = re.sub(r\"[^\\w\\s]\", \"\", text) \n",
    "\n",
    "# encode the text \n",
    "# 1. int2char, integers to characters\n",
    "# 2. char2int, characters to unique integers\n",
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "\n",
    "# encode the text\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LSTM(\n  (lstm): LSTM(224, 512, num_layers=3, batch_first=True, dropout=0.5)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc): Linear(in_features=512, out_features=224, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "n_hidden=512\n",
    "n_layers=3\n",
    "# default values \n",
    "drop_prob = 0.5\n",
    "lr=1\n",
    "bidirectional = False\n",
    "\n",
    "# load one of the models from models.py\n",
    "model = LSTM(chars, device, bidirectional, n_hidden, n_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Resuming lstm3_epoch.pt from epoch 5 ...\n",
      "Epoch: 5... Loss: 1.3181...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_length = 300\n",
    "n_epochs = 5 # small because for testing\n",
    "\n",
    "# train the model\n",
    "train_and_save(model, encoded, device, model_name='lstm3_epoch.pt', epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.0001, resume_from_saved=True, bidirectional=bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ja gozihanbálvalusas ja dušše go dat doaibmabijuiguin dárbbašuvvojit guovddáš servodateallima ja dutkandihke stuora dasa ahte sámi geavaheami dihtejit stuorra ovddideami doaitma mearrida sámi kultuvrra servodagas \\n Sámediggi go sámegillii \\nOlbmot dihto doarjja loahpalaččat \\n Doarjjaortnega bokte \\nSámediggi lea váldá dasa ahte sámi duoji oasit dan muhto guoskevaš ovddasvástádusa birra leat máksojuvvon go guovlluin leat dásseárvosuodjalusdearvvašvuođalága  ru sámi kulturmuitosuodjalusa oahppaneavtouorga johtui ja golmma ja ođđaáigásaš bušeahttamearkkaid giellaortnega dásis maid sámediggejoavku lea maiddái doarjaga oahpahusa deaŧalaš oassin lea dohkkehuvvon geavahit sámi ásahusaid birra mii lea dáin lága mat guoská oahppoplánaide ja dáiddáriiguin mat galget galget ollu go luondduguovddážis sáhttet ovddaskas stuorra doarjaga muhtun sámegielat mat leat mii oaidnit mielde dieđut guolástusdieđáhusa dan ovdánahttinguovlluid mielas lea meroštallojuvvon mii dain dahkkojuvvon sámi dáiddariikka ja oahppoplánaid mielde juolludanvuoigatvuođaid buoret dasa ahte dieđihuvvo sámi giella ja sámi guovlluid sámelága giellabajásdahkanahttinprinsihpa buktagiid galgá galggašii dat ahte gulaskuddan sámi kultuvrra geažil ja ovddastusas maiddái guolástus lea ovttasbargošágan luondduráđđádallama doaimmaid mat leat sámi dieđuid dat geavahanvejolašvuohta jođiheaddji dieđuin \\nDavviráđi muhto dan oktavuođas \\nOvttajagidii galgá leat sámi kulturmuitosuodjalusa ja ovttasbargguid stuorát ovddideapmái lea dievasčoahkkimis galgá leat deaŧalaš ovttasbargošiehtadusa bokte \\nDasto daid oahpponeavvobeili maŋŋá olbmuid joatkit dahje eanet doarjaga maiddái ovddiduvvot ovdal gielddaide \\nSámedikki vásáhus dohkkeha dan birra \\nDoaibmabijut \\n Sámikolitihka birra maid dáid gaskasaš doahpaga ja stáhtabargiide \\nSámediggi lea váikkuhit sámi kultuvrra sámi gielalaš dearvvašvuođa main meannudan guovlluid sámi gelbbolašvuođa sámi kulturárbbi sihke sámi giella ja giellaguovlluid gaskkas lea válljejuvvon dain doaimma mas leat '"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from predict import * \n",
    "\n",
    "model, _ , _, _, _, _  = load_checkpoint(\"lstm3_epoch.pt\", model, opt)\n",
    "\n",
    "show_sample(model, 2000, device, prime='ja', top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}