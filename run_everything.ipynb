{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### This notebook serves the purpose of running everithing in one go - train, save the model where you want, resume training, see the predictions etc.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_preprocess_input import *\n",
    "from models import *\n",
    "from train import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sme-freecorpus.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# clean very special char\n",
    "text = text.replace(\"¶\", \"\").replace('•', '').replace('□', '').replace('§', '').replace('\\uf03d', '').replace('π', '').replace('●', '').replace('µ', '').replace('º', '').replace('文', '').replace('中', '').replace('⅞', '').replace('½', '').replace('⅓', '').replace('¾', '').replace('¹', '').replace('³', '').replace('\\t', '')\n",
    "# remove numbers\n",
    "text = re.sub(r'[0-9]+', '', text)\n",
    "# remove russian texts (it is in data)\n",
    "text = re.sub(r\"[А-Яа-я]\", '', text) \n",
    "# remove puctuation\n",
    "text = re.sub(r\"[^\\w\\s]\", \"\", text) \n",
    "\n",
    "# encode the text \n",
    "# 1. int2char, integers to characters\n",
    "# 2. char2int, characters to unique integers\n",
    "chars = tuple(sorted(set(text))) \n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "\n",
    "# encode the text\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LSTM(\n  (emb): Embedding(224, 128)\n  (rnn): LSTM(128, 756, num_layers=3, batch_first=True, dropout=0.5)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc): Linear(in_features=756, out_features=224, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "n_hidden=756\n",
    "n_layers=3\n",
    "# default values \n",
    "drop_prob = 0.5\n",
    "lr=0.001\n",
    "bidirectional = False\n",
    "use_embeddings = True\n",
    "is_gru = False\n",
    "emb_dim = 128\n",
    "# load one of the models from models.py\n",
    "model = LSTM(chars, device, is_gru, bidirectional, use_embeddings, emb_dim, n_hidden, n_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting to train lstm_test.pt...\n",
      "Epoch: 1... Loss: 1.4159...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "seq_length = 300\n",
    "n_epochs = 1 # small because for testing\n",
    "\n",
    "# train the model\n",
    "train_and_save(model, encoded, device, model_name='lstm_test.pt', epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.0001, resume_from_saved=False, bidirectional=bidirectional, use_embeddings=use_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ja laht dea    ddera din   mahea má láli di geat galat  ma de lusa meast  didin  ge muoht  d   lasi did lu dea   mahuolidasea gea mera mi ddi didi ge gin  la  ddinin d lasalaha gu  latas litalá lera  mahkkkitahtiddas  mea goa lári d da   d la  dd ditta d  geastta mala dit  leatidina leralea maleatahuva láláhkta gatas mite dasi da  ge  d   linda da  dalaláht mide gas dasease luola  den ddddas  ddini lit la lui da   dalalat dati guseas lasteattahtasi lera mahtina d lase  la di lele mustt mahkii luohkuoa  me  govvva dalusalaht liinddelahkalahus maláreláhkahuolea dasaláin lasidditat dea lalas  meahat merealuvat  ddeaheliteahat mahas dahelahta mitt  ga  geahtas lat luselu diiit  guovole ddasaha  luvdeahkid     li deatat luoli mita  di  mea ga ga den   gi leaht la ga da ma lasididahuohala miin da  guorea goli  di ma luohkuidaht goa  ddin muoht gi delá gii  di guoluolat  lahtin mu midaliiiden  ddit gidea mi  geatiti laht den  gelin  meatida láida lálái gii   gat ma   ddena di ma ma dalaleatt luin mi laht dase  giiiti  must   la  leat  lea dasitt lusa máluvolus leala deráin da láhuiiteatt   mittahkuoat gi  luoráidi dea  dddatten  mi goluiidi la diitt    lu din las dea    me  la dahe muvvvdeli   meast de lat  d   gasi  dd   ge mi gui d gat git  ddaliti ga goasalin luvuolasale gi  mus gii  d laha li git da  derid lahku di láreala dendasa  ga dda  gahe dd di gast le dine li ddit  lat luid da mas  gui   d dahe ga lit diididda maht  gi dat lat   gasa guiddeas ga  málalatenea date   leastaseahea malit  mat meatt lasa    gasi  me  mi ma  de  dd last máhtti guova me  d     mea li la dalálaluvvatahkt da  daleaht mi  mea mii dde dasitea matea d gi dit  lea ddd deatttala da lahela goleat mea me liiiddeas da da   dat  la  dii maht  mii  gerelálálalálusergea lii leahta gii lalahtelalat ma  ga mi   geatt  gideahki dastiideas lu  dalui la midi da gitas   luvoahuoatea lahkteriida  ddii   gaht deahtt dii de  leat   gida diiddeas d gasat   lerasta  laleat ma  galea gus  de   la das  da dd   la '"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from predict import * \n",
    "\n",
    "model, _ , _, _, _, _  = load_checkpoint(\"lstm_test.pt\", model, opt)\n",
    "\n",
    "show_sample(model, 2000, device, use_embeddings=use_embeddings, prime='ja', top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}